{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cf138b-5411-4a02-beea-0cbcb33e0480",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Answer: 1\n",
    "    \n",
    "Ensemble methods are techniques that aim at improving the accuracy of results in models by combining\n",
    "multiple models instead of using a single model.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f756e2e6-06a6-4857-bb42-14e82b9c7527",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Answer: 2\n",
    "    \n",
    "The ensemble methods in machine learning help minimize these error-causing factors, thereby ensuring the accuracy \n",
    "and stability of machine learning (ML) algorithms    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f3b9a3-6335-4ef1-b8c3-1ab51f2a97d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Answer: 3\n",
    "    \n",
    "Bagging, also known as Bootstrap aggregating, is an ensemble learning technique that helps to improve the performance and accuracy of machine learning algorithms. \n",
    "It is used to deal with bias-variance trade-offs and reduces the variance of a prediction model.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ad7b68-c28c-47a8-82c6-9fe4173dc6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Answer: 4\n",
    "    \n",
    "Boosting is a method used in machine learning to reduce errors in predictive data analysis.\n",
    "Data scientists train machine learning software, called machine learning models, on labeled data to \n",
    "make guesses about unlabeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a35ef32-aeef-47ed-997d-c5ad347c437f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Answer: 5\n",
    "    \n",
    "-Ensemble methods have higher predictive accuracy, compared to the individual models.\n",
    "-Ensemble methods are very useful when there is both linear and non-linear type of data in the dataset; \n",
    " different models can be combined to handle this type of data.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d24a401-d2d3-4c2f-8005-e2025c3e9d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Answer: 6\n",
    "    \n",
    "Ensemble methods offer several advantages over single models, such as improved accuracy and performance, especially for complex and noisy problems. \n",
    "They can also reduce the risk of overfitting and underfitting by balancing the trade-off between bias and variance, and by using different subsets and features of the data.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db3aea0-502f-4d0b-926f-db83d7c162f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Answer: 7\n",
    "    \n",
    "Take n repeated random samples, with replacement, from the given dataset. ...\n",
    "Calculate the statistic of interest for each of these resamples, e.g. mean, median, standard deviation, etc.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8a597b-a618-4a1a-98c3-a1ec1dde7449",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Answer: 8\n",
    "    \n",
    "The bootstrap method involves iteratively resampling a dataset with replacement. \n",
    "That when using the bootstrap you must choose the size of the sample and the number of repeats. \n",
    "The scikit-learn provides a function that you can use to resample a dataset for the bootstrap method.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a958260-de5c-404b-ad02-22a38570a6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Answer: 9\n",
    "    \n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "sample_mean = 15  # mean height of sample\n",
    "sample_std = 2    # standard deviation of sample\n",
    "n = 50            # sample size\n",
    "\n",
    "# Number of bootstrap samples\n",
    "num_bootstraps = 1000\n",
    "\n",
    "# Generate bootstrap samples\n",
    "bootstrap_means = []\n",
    "for _ in range(num_bootstraps):\n",
    "    # Resample with replacement\n",
    "    resampled_data = np.random.normal(loc=sample_mean, scale=sample_std, size=n)\n",
    "    bootstrap_means.append(np.mean(resampled_data))\n",
    "\n",
    "# Calculate 95% confidence interval\n",
    "confidence_interval = np.percentile(bootstrap_means, [2.5, 97.5])\n",
    "\n",
    "print(\"95% Confidence Interval for Population Mean Height:\", confidence_interval)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
